# CT Log Benchmarks: Trillian vs. TesseraCT

[![Benchmark Status](https://github.com/patflynn/ctlog-benchmarks/actions/workflows/benchmark.yml/badge.svg)](https://github.com/patflynn/ctlog-benchmarks/actions/workflows/benchmark.yml)

A fully automated, reproducible benchmarking suite comparing the performance and cost-efficiency of [Trillian](https://github.com/google/trillian) (backed by Cloud SQL) and **TesseraCT** (backed by Spanner) on Google Cloud Platform.

## üìä Latest Benchmark Results

> **Note:** These results are automatically generated by the [Benchmark Workflow](.github/workflows/benchmark.yml).

| Metric | Trillian (MySQL) | TesseraCT (Spanner) |
| :--- | :--- | :--- |
| **Max Throughput** | 136.97 QPS | 1.00 QPS |
| **Latency (p95)** | *Pending* | *Pending* |
| **Cost per 1M Entries** | $181.8037 | $10243.9805 |
| **Storage Efficiency** | 0.0000 GB | 0.0000 GB |

*(Detailed run logs and cost breakdown can be found in the workflow artifacts)*

## üéØ Project Goals

1.  **Reproducibility:** The entire benchmark (Infrastructure -> Deploy -> Load Test -> Teardown) is a single GitHub Actions workflow.
2.  **Transparency:** "Derived Cost" is calculated in real-time based on resource provisioning, not just delayed billing reports.
3.  **Isolation:** Trillian and TesseraCT run on isolated Node Pools to ensure no CPU/Memory contention affects the results.

## üèó Architecture

This project uses a "GitOps-lite" approach where the repo contains everything needed to spin up a transient environment.

*   **Infrastructure:** Terraform (`/terraform`) manages the GKE cluster, Cloud SQL, Spanner, and GCS.
    *   *State:* Stored in GCS.
    *   *Bootstrap:* Long-lived auth resources (Workload Identity) are in `/terraform/bootstrap`.
*   **Deployment:** `ko` builds and pushes Go binaries directly to the cluster. Manifests are in `/k8s`.
*   **Orchestration:** Python scripts (`/scripts`) coordinate the benchmark:
    *   `deploy_k8s.sh`: Deploys the application stacks.
    *   `benchmark.py`: Runs the load generator (`ct_hammer`).
    *   `metrics.py`: Scrapes Cloud Monitoring for resource usage.

## üöÄ Running the Benchmark

This project is designed to run via **GitHub Actions**.

1.  Go to the **Actions** tab.
2.  Select the **Benchmark Execution** workflow.
3.  Click **Run workflow**.

The workflow will:
1.  Provision Infrastructure (Terraform).
2.  Deploy Applications (`ko`).
3.  Run Load Tests (`ct_hammer`).
4.  Update this `README.md` with new stats.
5.  Destroy Infrastructure (Cleanup).

## üõ† Local Development

**Prerequisites:**
*   Go 1.24+
*   Terraform 1.9+
*   `ko`
*   `gcloud` CLI

**Bootstrap (One-time):**
The `terraform/bootstrap` directory sets up the Workload Identity that allows GitHub Actions to talk to GCP.
